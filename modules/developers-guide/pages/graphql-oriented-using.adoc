= Using the Stargate GraphQL API (GraphQL-oriented)

Stargate is a data gateway deployed between client applications and a database.
The GraphQL API plugin that exposes CRUD access to data stored in Cassandra tables.

include::partial$graphql-oriented-desc.adoc[]

include::partial$GQLAPIBlogPost.adoc[]

// tag::prereqsList[]
include::partial$prereqs.adoc[]
// end::prereqsList[]

// not in astra yet
//include::developers-guide:partial$astra_tip.adoc[]

// tag::getDockerImage[]
include::partial$docker_pull.adoc[tag=3x]
// end::getDockerImage[]

// tag::startDocker[]
include::partial$docker_run.adoc[tag=3x]
// end::startDocker[]

== Using the Auth API to generate an auth token
In order to use the Stargate Document API, an authorization token must be
generated to access the interface. A REST API token is used for this purpose.

// generate the auth token
include::partial$gen_auth_token.adoc[]

You will need to add this token to the GraphQL Playground in order to authorize
your GraphQL requests. Copy the value after `"authToken"` to use later.

include::graphql.adoc[tag=UsingGraphQLPlayground]

include::graphql.adoc[tag=UsingPostman]

== Creating or dropping schema

In order to use the GraphQL API, you must xref:graphql-oriented-using.adoc##_deploying_schema[deploy schema]
that defines the types, mutations, and queries.
However, a keyspace, a container that stores the data, must first be created.

// tag::CreateKS[]
=== Creating a keyspace

Before you can start using the GraphQL API, you must first create a Cassandra
keyspace in your database.

// LLP: need to check how to write this - it's migration...If you are connecting to a Cassandra database with existing schema, you can skip this step.

Inside the GraphQL playground, navigate to
http://localhost:8080/graphql-schema[http://localhost:8080/graphql-schema]
and create a keyspace by executing the following mutation:

[source, plaintext]
----
include::example$graphql/createKeyspace.graphql[]
----
For each keyspace created in your Cassandra schema, a new path is created under
the `graphql-path` root (default is: `/graphql`). For example, the mutation just
executed creates a path `/graphql/library` for the `library` keyspace when
Cassandra creates the keyspace.

Add the auth token to the HTTP Headers box in the lower lefthand corner:

[source, plaintext]
----
{
  "X-Cassandra-Token":"bff43799-4682-4375-99e8-23c8a9d0f304"
}
----

[IMPORTANT]
====
Notice that the key for this JSON token is different than the value that the
generate token has. It is `X-Cassandra-Token`, not `auth-token`.
====

Now run the mutation to create the keyspace. You should see a return value of:

[source, plaintext]
----
include::example$result/gql_createKeyspace.result[]
----
// end::CreateKS[]


//LLP: now I'm discussing graphql types from here on

// tag::CreateUDT[]
=== Creating a user-defined type (UDT)

User-defined types (UDTs) can be created as GraphQL object types.
UDTs are optional, but if you wish to use a UDT in another object type definition,
you'll want to create the UDT first.
Once created, you can include the type in the schema deployed via the GraphQL playground.
Here are two examples that create a UDT called `Address` that includes a street, city, state, and zipcode,
and a UDT called `Review` that includes a book title, comment, rating and review data.

[tabs]
====
Address UDT::
+
--
[source,shell]
----
include::example$graphql/1createUDTAddress.graphql[]
----
--

Review UDT::
+
--
[source,shell]
----
include::example$graphql/1createUDTReview.graphql[]
----
--
====

// USE asciidoc callouts to explain? a la https://docs.couchbase.com/home/contribute/code-blocks.html#callouts
These types have some Cassandra-specific features, in addition to the typical format
of a GraphQL type.
To denote that the type will be stored as a UDT in Cassandra, `@cql_entity(target: UDT)`
is added to the initial line.

To avoid duplicating the type as both an input type and output type, `@cql_input` is
added to make the type an input type.

Standard CamelCase is used to name the fields, but the Cassandra column name can be
named with an alternative using `@cql_column(name: "book_title")`.
In Cassandra, CamelCase names must be double-quoted, so this particular field name is
both GraphQL friendly (bookTitle) and CQL friendly (book_title).

==== Data types

A column's CQL data type is inferred from the GraphQL field type.
GraphQL's built-in scalar types are mapped:

[options="header",footer"]
|====
| GraphQL | CQL
| ID      | uuid
| String  | varchar
| Int     | int
| Float   | double
| Boolean | boolean
|====

In addition, Stargate provides a set of custom scalar types that map directly
to the CQL types of the same name:
Uuid, TimeUuid, Inet, Date, Duration, BigInt, Counter, Ascii, Decimal, Varint,
Float32, Blob, SmallInt, TinyInt, Timestamp, Time.

Sets and lists are defined by custom typed arrays. Maps and tuples are not
supported, but UDTs can be used to create the same functionality.

// end::CreateUDT[]

// tag::CreateObjectTypes[]
=== Creating object types

The most basic components of a GraphQL schema are object types, which just
represent a kind of object you can fetch from your service, and specify the
fields contained in the object.

[tabs]
====
Book type::
+
--
[source,shell]
----
include::example$graphql/1createTableBook.graphql[]
----
--

Reader type::
+
--
[source,shell]
----
include::example$graphql/1createTableReader.graphql[]
----
--
====

Although the types defined for UDTs and these examples are not fundamentally different,
a few new features are illustrated here.

In the Book type, there are additional `@cql_column` parameters defined.
It is possible to define the partition key and clustering keys are shown, by
using `partitionKey: true` and `clusteringOrder: ASC`, respectively.
The default clustering order is `ASC`, or ascending.
Information about partition keys and clustering keys can be found in the
https://cassandra.apache.org/doc/latest/cql/[CQL reference].

A standard GraphQL type feature is displayed in these types, the required fields
denoted by `String!` and `Uuid!` that include the exclamation mark.

The fields `reviews` and `address` are defined as arrays by the addition of square brackets,
`reviews: [Review]`.
Note that these two fields are arrays of the UDTs previously defined.

Lastly, `@cql_column` can be used to provide a hint to Cassandra that specifies
custom field types, such as a set of strings, `@cql_column(typeHint: "set<varchar>")`.
// end::CreateObjectTypes[]

// tag::CreateQueries[]
=== Create queries

Most types in your schema will just be normal object types, but there are two types
that are special, the Query type and the Mutation type.
Every GraphQL service has a query type.
Mutation types are optional.
These types are special because they define the entry point of every GraphQL query.

Queries

[tabs]
====
Query type::
+
--
[source,shell]
----
include::example$graphql/1createQuery.graphql[]
----
--
====

These queries each specify the fields required and optional, as well as the input
type.

In the case of `book`, `title` is a required column, and `author` is an optional field
input to retrieve a particular book. Because you specified `@cql_input` in the
object type, `Book` specifies the input type.
// end::CreateQueries[]

// tag::CreateMutations[]
=== Create mutations

Mutations work in a similar way  to queries.
Define fields in the mutation type, and you can specify those fields in your queries.

[tabs]
====
Book type::
+
--
[source,shell]
----
include::example$graphql/1createOperations.graphql[]
----
--
====

For mutations, notice the use of the input type `book:BookInput!` to define that the
type submitted to the mutation is a `book`.
`insertBook` will insert a book, `insertReader` will insert a reader, and `deleteBook`
and `deleteReader` are Boolean operations.
// end::CreateMutations[]

// tag::DeploySchema[]
== Deploying schema

=== Deploy schema manually

Now that you have created GraphQL types, queries, and mutations, it's time to deploy the schema.
Recall that the corresponding CQL schema is inferred and created from the GraphQL schema
submitted.

Inside the GraphQL playground, navigate to http://localhost:8080/graphql-admin and create
the schema to deploy to a previously defined keyspace:

[tabs]
====
graphQL command::
+
--
[source,shell]
----
include::example$graphql/1createDeploy.graphql[]
----
--

Result::
+
--
[source,plaintext]
----
include::example$result/gql_1createDeploy.result[]
----
--
====

A defined mutation `deploySchema` is executed.
The keyspace is specified, along with the schema, specified between triple quotes (`"""`).

A number of additional options are used in the following manner:
|====
| Option | Default | Description
| expectedVersion | N/A | Each schema is assigned a unique version number. If the current deployment is a modification, the version must be supplied.
| dryRun | false | To test in a dryrun, use `dryRun: true`
| force | false |Force a schema change
| migrationStrategy | No | USE_EXISTING, ADD_MISSING_TABLES, ADD_MISSING_TABLES_AND_COLUMNS, DROP_AND_RECREATE_ALL, DROP_AND_RECREATE_IF_MISMATCH
|====

Two items are returned in this example, the `version` that is assigned to the schema,
and `cqlChanges`, the status of whether CQL changes occurred due to the schema deployment.
Other responses are `logs` and `query`.


=== Deploy schema file

Schema can also be deployed to a keyspace using a schema file upload.
This mutation must be executed with a multipart request (note that your operations
  part must declare MIME type application/json).

In this case, `deploySchemaFile` is executed. This query must be executed in the command line
with a cURL command:

[tabs]
====
graphQL command::
+
--
[source,shell]
----
include::example$graphql/1createDeployFile.graphql[]
----
--

Result::
+
--
[source,plaintext]
----
include::example$result/gql_1createDeployFile.result[]
----
--
====
The operations part contains the GraphQL payload. It consists of a
parameterized mutation, which takes a single `$file` argument (note that we
  leave it as null in the payload, because it's going to be set another way).
The `filePart` argument contains the file.
The `map` argument specifies which file goes into which GraphQL variable.

=== Modify schema

To modify the current schema, simply deploy again, supplying the `expectedVersion` as the
current schema's version if you wish to overwrite the definitions. Otherwise, a new schema
with a new version id will be created.
// end::DeploySchema[]


// tag::CheckKSSchema[]
== Checking the keyspace schema

To check if the schema exists, execute a GraphQL check in http://localhost:8080/graphql-admin:

For all versions of a keyspace schema:

[tabs]
====
graphQL command::
+
--
[source,shell]
----
include::example$graphql/1getAllKsSchema.graphql[]
----
--

Result::
+
--
[source,plaintext]
----
include::example$result/gql_1getAllKsSchema.result[]
----
--
====

For a particular version of a keyspace schema:

[tabs]
====
graphQL command::
+
--
[source,shell]
----
include::example$graphql/1getParticularKsSchema.graphql[]
----
--

Result::
+
--
[source,plaintext]
----
include::example$result/gql_1getParticularKsSchema.result[]
----
--
====

// end::CheckKSSchema[]

// tag::UndeploySchema[]
== Undeploying schema

To undeploy an existing schema, use the following mutation.

[tabs]
====
graphQL command::
+
--
[source,shell]
----
include::example$graphql/1Undeploy.graphql[]
----
--

Result::
+
--
[source,plaintext]
----
include::example$result/gql_1Undeploy.result[]
----
--
====

The keyspace name and schema version must be supplied.
One option is available, `force`, to force an erasure of the schema.
// end::UndeploySchema[]

== Interacting with data stored in tables

// tag::WriteData[]
=== Write data

If you have created schema for insertion, now you are ready to write data into the database.

First, let's navigate to your new keyspace `library` inside the playground.
Change the location to
http://localhost:8080/graphql/library[http://localhost:8080/graphql/library]
and add a couple of books to the `book` table:

[tabs]
====
graphQL command::
+
--
[source,shell]
----
include::example$graphql/1insert2Books.graphql[]
----
--

Result::
+
--
[source,plaintext]
----
include::example$result/gql_1insert2Books.result[]
----
--
====

The insertion is straightforward.
The title and author are specified, and the title is returned in response to a successful insertion.
Only the required fields must be specified, and any fields can be returned in the reponse.
This same operation can be used to update the stored data, as insertions are upserts in all cases.

// LLP: ********** I  NEED TO ADD A CONDITIONAL IFNOTEXISTS INSERT! ********

// end::WriteData[]

// COMMENTED OUT FOR NOW - NOT IMPLEMENTED BUT MAY BE, SO LEAVE THE TEXT
// tag::WriteAdvData[]
//==== Insertion options

//Three insertion options are configurable during data insertion or updating:

//* https://docs.datastax.com/en/dse/6.8/dse-arch/datastax_enterprise/dbInternals/dbIntConfigConsistency.html[consistency level]
//* https://docs.datastax.com/en/dse/6.8/dse-arch/datastax_enterprise/dbInternals/dbIntConfigSerialConsistency.html[serial consistency level]
//* https://docs.datastax.com/en/dse/6.8/cql/cql/cql_using/useExpire.html[time-to-live (TTL)]

//An example insertion that sets the consistency level and TTL:

//[tabs]
//====
//graphQL command::
//+
//--
//[source,shell]
//----
//include::example$graphql/insertBookWithOption.graphql[]
//----
//--

//Result::
//+
//--
//[source,plaintext]
//----
//include::example$result/gql_insertBookWithOption.result[]
//----
//--
//====

//The serial consistency can also be set with `serialConsistency` in the options,
//if needed.

==== Insert arrays and UDTs

Inserting arrays and UDTs requires a few extra embellishments:

[tabs]
====
graphQL command::
+
--
[source,shell]
----
include::example$graphql/1insert2Readers.graphql[]
----
--

Result::
+
--
[source,plaintext]
----
include::example$result/gql_1insert2Readers.result[]
----
--
====

Note the use of square brackets around arrays of objects, with commas separating
array items.
// end::WriteAdvData[]

// tag::ReadData[]
=== Read data

Let's check that the data was inserted.

// LLP: Get all book data - add a query

Now let's search for a particular record using a `WHERE` clause. The primary
key of the table can be used in the `WHERE` clause, but non-primary key columns
cannot be used.
The following query, looking at the location
http://localhost:8080/graphql/library[http://localhost:8080/graphql/library]
will get both the `title` and the `author` for the specified book `WHERE
title:"Moby Dick"`:

[tabs]
====
graphQL command::
+
--
[source,shell]
----
include::example$graphql/readOneBook.graphql[]
----
--

Result::
+
--
[source,plaintext]
----
include::example$result/gql_readOneBook.result[]
----
--
====

// end::ReadData[]

// tag::ReadAdvData[]

To find multiple books, an addition to the `WHERE` clause is required, to denote that
the list of titles desired is `IN` a group:

[tabs]
====
graphQL command::
+
--
[source,shell]
----
include::example$graphql/readThreeBooks.graphql[]
----
--

Result::
+
--
[source,plaintext]
----
include::example$result/gql_readThreeBooks.result[]
----
--
====

To display the contents of a UDT, notice the inclusion of `addresses` in the values displayed for this read query:

[tabs]
====
graphQL command::
+
--
[source,shell]
----
include::example$graphql/readReaderWithUDT.graphql[]
----
--

Result::
+
--
[source,plaintext]
----
include::example$result/gql_readReaderWithUDT.result[]
----
--
====

To display the contents of a map collection, notice the inclusion of `earned` in the values displayed for this read query:

[tabs]
====
graphQL command::
+
--
[source,shell]
----
include::example$graphql/readOneGoldBadge.graphql[]
----
--

Result::
+
--
[source,plaintext]
----
include::example$result/gql_readOneGoldBadge.result[]
----
--
====
==== Filter options for reading

The filters available are:

* eq (equal)
* notEq (not equal)
* gt (greater than)
* gte (greater than or equal to)
* lt (less than)
* lte (less than or equal to)
* in (within)
* contains (a map contains the specified value)
* containsKey (a map contains the specified key)
* containsEntry (a map contains the specified key:value pair)

Note that these can only be used with primary key columns, just like in Cassandra, unless
indexing is created.

The next examples will query the same table, `badge`, using a variety of filters to illustrate
the versatility of such filters.
The first example finds the record that has the partition key `badge_type` equal to `Gold`, and
the `badge_id` equal to `100`:

[tabs]
====
graphQL command::
+
--
[source,shell]
----
include::example$graphql/readOneGold100Badge.graphql[]
----
--

Result::
+
--
[source,plaintext]
----
include::example$result/gql_readOneGold100Badge.result[]
----
--
====

Now if we use a different operator `gt` with the same query, notice that the query will fail,
because no `badge_id` greater than a value of 100 is found:

[tabs]
====
graphQL command::
+
--
[source,shell]
----
include::example$graphql/readOneGoldGT100Badge.graphql[]
----
--

Result::
+
--
[source,plaintext]
----
include::example$result/gql_readOneGoldGT100Badge.result[]
----
--
====

In order to use filters for any columns that are not part of the primary key, currently
you need to use CQL to create a secondary index using the CQL shell.
The next three examples show the CQL creation of an index in order to query a column
that is a map collection.

In this example, an index is created on the keys of the map `earned`, so the `containsKey`
filter can be used to query in GraphQL.

[tabs]
====
graphQL command::
+
--
[source,shell]
----
include::example$graphql/readOneWriterBadge.graphql[]
----
--

Result::
+
--
[source,plaintext]
----
include::example$result/gql_readOneWriterBadge.result[]
----
--
====

Because the index now exists, it is also possible to just filter based on the map key itself:

[tabs]
====
graphQL command::
+
--
[source,shell]
----
include::example$graphql/readOneWriterKeyBadge.graphql[]
----
--

Result::
+
--
[source,plaintext]
----
include::example$result/gql_readOneWriterKeyBadge.result[]
----
--
====

In this next example, an index is created on the values of the map `earned`, so the `contains`
filter can be used to query in GraphQL.

[tabs]
====
graphQL command::
+
--
[source,shell]
----
include::example$graphql/readOneWriterValueBadge.graphql[]
----
--

Result::
+
--
[source,plaintext]
----
include::example$result/gql_readOneWriterValueBadge.result[]
----
--
====

To make a complete set of filters, an index is created on the entries of the map `earned`, so the `containsEntry`
filter can be used to query in GraphQL.

[tabs]
====
graphQL command::
+
--
[source,shell]
----
include::example$graphql/readOneWriterEntryBadge.graphql[]
----
--

Result::
+
--
[source,plaintext]
----
include::example$result/gql_readOneWriterEntryBadge.result[]
----
--
====

// end::ReadAdvData[]

// tag::UpdateData[]
=== Update data

Using the column that we added earlier, the data for a book is updated with the
`ISBN` value:

[tabs]
====
graphQL command::
+
--
[source,shell]
----
include::example$graphql/updateOneBook.graphql[]
----
--

Result::
+
--
[source,plaintext]
----
include::example$result/gql_updateOneBook.result[]
----
--
====

[NOTE]
====
Updates are upserts. If the row doesn't exist, it will be created.
If it does exist, it will be updated with the new row data.
====
// end::UpdateData[]

// tag::UpdateAdvData[]
It is also possible to update other types of data, such as a set:

[tabs]
====
graphQL command::
+
--
[source,shell]
----
include::example$graphql/updateOneBookAgain.graphql[]
----
--

Result::
+
--
[source,plaintext]
----
include::example$result/gql_updateOneBookAgain.result[]
----
--
====
// end::UpdateAdvData[]

// tag::DeleteData[]
=== Delete data

After adding the book "Pride and Prejudice" with an `insertBooks()`, you can delete
the book using `deleteBooks()` to illustrate deleting data:

////
The insertion is:
mutation insertAnotherBook {
  PaP: insertbook(value: {title:"Pride and Prejudice", author:"Jane Austen"}) {
    value {
      title
    }
  }
}
////

[tabs]
====
graphQL command::
+
--
[source,shell]
----
include::example$graphql/deleteOneBook.graphql[]
----
--

Result::
+
--
[source,plaintext]
----
include::example$result/gql_deleteOneBook.result[]
----
--
====

Note the use of `ifExists` to validate that the book exists before deleting it.
// end::DeleteData[]

// tag::DeleteAdvData[]
==== Deletion options

Similar to the option `ifExists`, you can delete a book using `consistency`,
`serialConsistency`, or `ttl`, similar to insertions:

////
The insertion is:
mutation insertAnotherBook {
  PaP: insertbook(value: {title:"Pride and Prejudice", author:"Jane Austen"}) {
    value {
      title
    }
  }
}
////

[tabs]
====
graphQL command::
+
--
[source,shell]
----
include::example$graphql/deleteOneBookCL.graphql[]
----
--

Result::
+
--
[source,plaintext]
----
include::example$result/gql_deleteOneBookCL.result[]
----
--
====

// end::DeleteAdvData[]

////
I'll need a section that shows how connecting to an existing C* cluster will automatically
create the graphql endpoints!
////
