= Using the Stargate GraphQL API (Schema-first)

Stargate is a data gateway deployed between client applications and a database.
The GraphQL API plugin that exposes CRUD access to data stored in Cassandra tables.

include::partial$graphql-first-desc.adoc[]

include::partial$GQLAPIBlogPost.adoc[]

// tag::prereqsList[]
include::partial$gql-prereqs.adoc[]
// end::prereqsList[]

// not in astra yet
//include::developers-guide:partial$astra_tip.adoc[]

// tag::getDockerImage[]
include::partial$docker_pull.adoc[tag=3x]
// end::getDockerImage[]

// tag::startDocker[]
include::partial$docker_run.adoc[tag=3x_graphql-first]
// end::startDocker[]

== Use the Auth API to generate an auth token
In order to use the Stargate GraphQL API, an authorization token must be
generated to access the interface. A REST API token is used for this purpose.

// generate the auth token
include::partial$gen_auth_token.adoc[]

You will need to add this token to authorize your GraphQL requests, either
executing cURL commands or using the GraphQL Playground.
Copy the value after `"authToken"` to use later.

include::partial$curl_and_graphQL.adoc[]

All examples on this page will use the GraphQL Playground, with some exceptions
using cURL commands.

== Create or delete schema

In order to use the GraphQL API, you must xref:graphql-first-using.adoc#_deploy_schema[deploy schema]
that defines the types, mutations, and queries.

// tag::CreateKS[]
=== Create a keyspace

Before you can start using the GraphQL API, you must first create a Cassandra
keyspace in your database. The keyspace is a container that stores data
with replication.

Inside the GraphQL playground, navigate to
http://localhost:8080/graphql-schema[http://localhost:8080/graphql-schema]
and create a keyspace by executing the following mutation:

[source, plaintext]
----
include::example$graphql/createKeyspace.graphql[]
----
For each keyspace created in your Cassandra schema, a new path is created under
the `graphql-path` root (default is: `/graphql`). For example, the mutation just
executed creates a path `/graphql/library` for the `library` keyspace when
Cassandra creates the keyspace.

Add the auth token to the HTTP Headers box in the lower lefthand corner:

[source, plaintext]
----
{
  "X-Cassandra-Token":"bff43799-4682-4375-99e8-23c8a9d0f304"
}
----

[IMPORTANT]
====
Notice that the key for this JSON token is different than the value that the
generate token has. It is `X-Cassandra-Token`, not `auth-token`.
====

Now run the mutation to create the keyspace.
You should see a return value of:

[source, plaintext]
----
include::example$result/gql_createKeyspace.result[]
----
// end::CreateKS[]

// tag::DeleteKS[]
=== Delete a keyspace

You can delete a keyspace. All tables and table data will be deleted along with
the keyspace schema.

[source, plaintext]
----
include::example$graphql/dropKeyspace.graphql[]
----
// end::DeleteKS[]

=== A note about what schema is

A full GraphQL schema that will be
xref:graphql-first-using.adoc#_deploy_schema[deployed] can
include user-defined types (UDTs), object types, indexes, queries, mutations, and payload
types. The next sections describes the definition of these items before discussing
how to deploy the schema once created.

[TIP]
====
Do you want to understand deployment first?
Read xref:graphql-first-using.adoc#_deploy_schema[Deploy Schema].
====



// tag::DataTypes[]
=== Data types

A column's CQL data type is inferred from the GraphQL field type.
GraphQL's built-in scalar types are mapped:

[options="header",footer"]
|====
| GraphQL | CQL
| ID      | uuid
| String  | varchar
| Int     | int
| Float   | double
| Boolean | boolean
|====

In addition, Stargate provides a set of custom scalar types that map directly
to the CQL types of the same name:
Uuid, TimeUuid, Inet, Date, Duration, BigInt, Counter, Ascii, Decimal, Varint,
Float32, Blob, SmallInt, TinyInt, Timestamp, Time.

Sets and lists are defined by custom typed arrays. Maps and tuples are not
supported, but UDTs can be used to create the same functionality.

In GraphQL syntax, square brackets denote an array, such as `email: [String]`
defines a field named email that is an array of String values.
Additionally, if an exclamation point follows a data type, such as `String!`,
then the field cannot contain a null value.
// end::DataTypes[]

// tag::CreateObjectTypes[]
=== Create object types

The most basic components of a GraphQL schema are object types, which just
represent a kind of object you can fetch from your service, and specify the
fields contained in the object.
Object types also have
link:https://www.graphql-tools.com/docs/schema-directives/[directives], which
are identifiers preceded by an `@` character.
Directives are GraphQL server-specific, and implemented in the server.
Stargate implements directives that are specific to the Apache Cassandra
backend, as well as Apollo data federation-specific directives that allow Stargate
to work with the Apollo gateway.

[tabs]
====
Book type::
+
--
[source,shell]
----
include::example$graphql/1createTableBook.graphql[]
----
--

Reader type::
+
--
[source,shell]
----
include::example$graphql/1createTableReader.graphql[]
----
--
====

Directives in example:

<1> Book: `@key` defines the fields that uniquely identify an object.
Stargate assigns primary key fields automatically as `@key` fields.
For other servers, the fields must be identified in a string, such as `@key(fields: "title isbn")`.
Required for Apollo data federation.
<2> Book: `@cql_entity(name: "book")` defines an alternate table name for the underlying database.
Cassandra, Astra DB, and DataStax Enterprise all require double-quotes around table names
that are CamelCase.
Changing the name to lowercase makes the object name both  GraphQL-friendly (`Book`) and CQL-friendly (`book`).
Not required.
<3> Book: `@cql_input` generates a `BookInput` type with the same fields as the type `Book`
in the GraphQL schema, without duplicating the object type in the schema.
Not required but strongly suggested to make writing queries and mutations easier.
<4> Book: `@cql_column(partitionKey: true)` sets the field to a partition key in the underlying database table.
This directive must be used for each field that comprises the partition key.
*IMPORTANT:* If no field has a `partitionKey: true`, but the first field is of data type
ID, Uuid, or TimeUuid, then that field is used as the partition key in the database.
Information about partition keys and clustering keys can be found in the
https://cassandra.apache.org/doc/latest/cql/[CQL reference].
<5> Book: `@cql_column(partitionKey: true, name: "book_title")` also sets the field name to an
alternate value that is CQL-friendly. Note the comma-separated items in @cql_column.
Column renaming is not required.
<6> Book: `@cql_column(clusteringOrder: ASC)` sets the field to a clustering column in the underlying database table.
This directive must be used for each field that is a clustering column.
The default clustering order is `ASC`, or ascending.
Not required.
<7> Book: `@cql_index(name: "author_idx", target: VALUES)` creates an index of the list of author names,
using the values listed in the array.
Note that the parameter `target` is required for arrays (set, list).
Required if queries will use the field as a parameter to retrieve data.
<8> Reader: `@cql_index(name: "date_idx")` creates an index of the birthdates.
Note that no target is required.
The `@cql_index` is discussed in xref:graphql-first-using.adoc#_create_indexes[Create indexes].
Not required.
<9> Reader: `@cql_column(typeHint: "set<varchar>")` sets the column data type to a set.
The only valid defaults are `set` or making a CQL type `frozen`.
Required if the field is a set or list.

The fields `author`, `reviews`, `address` are defined as arrays by the addition of square brackets,
`reviews: [Review]`.
Note that `reviews` and `addresses` are arrays of xref:graphql-first-using.adoc_create_a_user_defined_type_udt[UDTs]
whereas `author` is a list of Strings to name each author.
// end::CreateObjectTypes[]

// tag::CreateUDT[]
=== Create a user-defined type (UDT)

User-defined types (UDTs) can be created as GraphQL object types.
UDTs are optional, but if you wish to use a UDT in another object type definition,
you'll want to create the UDT first.
Once created, you can include the type in the schema deployed via the GraphQL playground.
Here are two examples that create a UDT called `Address` that includes a street, city, state, and zipcode,
and a UDT called `Review` that includes a book title, comment, rating and review data.

[tabs]
====
Address UDT::
+
--
[source,shell]
----
include::example$graphql/1createUDTAddress.graphql[]
----
--

Review UDT::
+
--
[source,shell]
----
include::example$graphql/1createUDTReview.graphql[]
----
--
====

Directives in example:

<1> The `@cql_entity(target: UDT)` denotes that the type is stored as a user-defined type (UDT)
in the underlying database table.
// end::CreateUDT[]

// tag::CreateIndex[]
=== Create an index

Cassandra supports indexing any regular, non-primary key fields in an object type.
Any field designated as a partition key or clustering column cannot be indexed,
unless DataStax Enterprise is the defined database.
A field will  be indexed if `@cql_index` is added to the field definition.
Indexed fields can be used as parameters in queries.

[tabs]
====

Reader type::
+
--
[source,shell]
----
include::example$graphql/1createReaderIndex.graphql[]
----
--
====

The directive `@cql_index` has the following optional arguments:

|====
| Argument  | Default | Description
| name | Generated | Custom index name.
| class | Secondary index | Custom index class, such as SAI.
| target | VALUES | Specifies set and list index type. Options are FULL and VALUES.
| options | N/A | Any options to pass to the underlying index query.
|====
// end::CreateIndex[]

// tag::CreateQueries[]
=== Create queries

Most types in your schema will just be normal object types, but there are two types
that are special, the Query type and the Mutation type.
Every GraphQL service has at least one query type.
Mutation types are optional.

Queries

[tabs]
====
Queries::
+
--
[source,shell]
----
include::example$graphql/1createQuery.graphql[]
----
--
====

<1> This query is named `bookByTitleAndIsbn`, with inputs `title` (non-null String value) and `isbn` (String value),
and outputs an array of objects of type Book.
<2> This query is named `readerByNameAndUserid`, with inputs `name` (non-null String value) and `user_id` (Uuid value),
and outputs an array of objects of type Reader.
// end::CreateQueries[]

// tag::CreateMutations[]
=== Create mutations

Mutations work in a similar way  to queries.
An input and output is defined.

[tabs]
====
Mutations::
+
--
[source,shell]
----
include::example$graphql/1createOperations.graphql[]
----
--
====

<1> An input of `BookInput!` is required, and must include the required fields as defined
by the `Book` object type. The output is a `Book` object.
<2> An input of `BookInput!` is required, and must include the required fields as defined
by the `Book` object type. The output is a Boolean value.
<3> The `@cql_update` directive makes this mutation an update, rather than an insert.

The `insert` mutation will insert an object of the specified type, and the `update`
and `delete` mutations will return a Boolean value.
If the `update` or `delete` mutation names begin with those words, the `@cql_update` directive
is not required.

==== Conditional insertion

A mutation can be turned into a conditional insertion operation by ending the mutation
name with `ifNotExists`.
However, it may be useful to know if the insertion is successfully applied.
In that case, see payload type below to see how a boolean field `applied` can
be added to the response from insertions or annotating it with `@cql_insert(ifNotExists: true)`.
// end::CreateMutations[]

// tag::CreatePayloadTypes[]
=== Create payload types

Payloads types are not mapped to the database, and only serve as wrappers of an operation's response.
They typically pass a more complex object than just an entity. For example,
you can add fields that check the `applied` status for a conditional query, or
the `pagingState`.

In this example, a payload type `SelectBookResult` is created that accepts an array
of books as the input. The associated query can use the required `title` and optional `pagingState`
as input, and will return an array of books along with the `pagingState`.

[tabs]
====
Payload type::
+
--
[source,shell]
----
include::example$graphql/1createQueryPageSize.graphql[]
----
--
====

Directives in example:

<1> The `@cql_payload` directive defines the type as a payload.
<2> The `@cql_pagingState` directive defines the fields as a storing a paging state.
<3> The `@cql_select(pageSize: 10)` directive defines how many results to return by
page if the query is paginated, with an Integer input.
Another parameter is also available, `limit: 10`, which is the maximum total number of
results to return, with an Integer input.

An example of retrieving data using this query is found xref:graphql-first-using.adoc#_retrieve_data[below].

Often, you wish to know if an operation was successful. Creating a payload type that
uses a boolean field `applied` can definitively answer if a conditional operation
completes correctly.

Create a payload type that uses your standard object type as a field, along with `applied`:

[tabs]
====
Payload type with conditional::
+
--
[source,shell]
----
include::example$graphql/1createPayloadConditional.graphql[]
----
--
====

If the conditional insert is successful (the row did not exist), then applied
will be true and book will echo back the data that was just inserted;
otherwise, applied will be false and book will be the existing data.
// end::CreatePayloadTypes[]

// tag::DeploySchema[]
== Deploy or undeploy schema

=== Deploy schema manually

Now that you have created GraphQL types, queries, and mutations, it's time to deploy the schema.
Recall that the corresponding CQL schema is inferred and created from the GraphQL schema
submitted.

[NOTE]
====
A keyspace will be created as xref:graphql-using.adoc[CQL-first] unless a schema is deployed.
After a schema is deployed, the keyspace should be accessed as schema-first.
====

Inside the GraphQL playground, navigate to http://localhost:8080/graphql-admin and create
the schema to deploy to a previously defined keyspace:

[tabs]
====
Simple graphQL schema command::
+
--
[source,shell]
----
include::example$graphql/1createDeploySimple.graphql[]
----
--

Simple result::
+
--
[source,plaintext]
----
include::example$result/gql_1createDeploy.result[]
----
--

Full schema command::
+
--
[source,shell]
----
include::example$graphql/1createDeploy.graphql[]
----
--
====

A defined mutation `deploySchema` is executed.
The keyspace is specified, along with the schema, specified between triple quotes (`"""`).

A number of additional options are used in the following manner:

|====
| Option | Default | Description
| expectedVersion | N/A | Each schema is assigned a unique version number. If the current deployment is a modification, the version must be supplied.
| dryRun | false | To test in a dryrun, use `dryRun: true`
| force | false |Force a schema change
| migrationStrategy | ADD_MISSING_TABLES_AND_COLUMNS | USE_EXISTING, ADD_MISSING_TABLES, ADD_MISSING_TABLES_AND_COLUMNS, DROP_AND_RECREATE_ALL, DROP_AND_RECREATE_IF_MISMATCH
|====

Two items are returned in this example, the `version` that is assigned to the schema,
and `cqlChanges`, the status of whether CQL changes occurred due to the schema deployment.
Other responses are `logs` and `query`.

The `migrationStrategy` option needs further explanation on how `deploySchema`
updates the underlying CQL schema, based on the options argument.
The available strategies are:

ADD_MISSING_TABLES_AND_COLUMNS (default)::
Create CQL tables and UDTs that don't already exist.
For those that exist, add any missing columns.
Partition keys and clustering columns cannot be added after initial creation.
This strategy will fail if the column already exists with a different data type.
USE_EXISTING::
Don't do anything. This is the most conservative strategy.
All CQL tables and UDTs must match, otherwise the deployment is aborted.
ADD_MISSING_TABLES::
Create CQL tables and UDTs that don't already exist.
Those that exist must match, otherwise the deployment is aborted.
DROP_AND_RECREATE_ALL::
Drop and recreate all CQL tables and UDTs.
This is a destructive operation: any existing data will be lost.
DROP_AND_RECREATE_IF_MISMATCH::
Drop and recreate only the CQL tables and UDTs that don't match.
This is a destructive operation: any existing data in the recreated tables will be lost.
Tables that are not recreated will retain their data.

=== Deploy schema file using cURL

Schema can also be deployed to a keyspace using a schema file upload.
This mutation must be executed with a multipart request (note that your operations
  part must declare MIME type application/json).

In this case, `deploySchemaFile` is executed. This query must be executed in the command line
with a cURL command:

[tabs]
====
graphQL command::
+
--
[source,shell]
----
include::example$graphql/1createDeployFile.graphql[]
----
--

Result::
+
--
[source,plaintext]
----
include::example$result/gql_1createDeployFile.result[]
----
--
====
The operations part contains the GraphQL payload. It consists of a
parameterized mutation, which takes a single `$file` argument (note that we
  leave it as null in the payload, because it's going to be set another way).
The `filePart` argument contains the file.
The `map` argument specifies that the file specified by `filePart` will map
to the `variables.file` setting.
In this example, the schema file supplied is located in `/tmp/schema.graphql`.

In order to deploy a schema file again, you'll need to supply the `expectedVersion`
for the schema to be replaced.
xref:graphql-first-using.adoc#_check_the_keyspace_schema[Check the keyspace schema]
to get the current version.

[tabs]
====
graphQL command::
+
--
[source,shell]
----
include::example$graphql/1DeployFileAgain.graphql[]
----
--

Result::
+
--
[source,plaintext]
----
include::example$result/gql_1DeployFileAgain.result[]
----
--
====

=== Modify schema

To modify the current schema, simply deploy again, supplying the `expectedVersion` as the
current schema's version if you wish to overwrite the definitions.
Otherwise, a new schema with a new version id will be created.
Either the GraphQL Playground or the cURL command can be used to update the schema.
// end::DeploySchema[]


// tag::CheckKSSchema[]
=== Check the keyspace schema

To check if the schema exists, execute a GraphQL check in http://localhost:8080/graphql-admin:

For all versions of a keyspace schema:

[tabs]
====
graphQL command::
+
--
[source,shell]
----
include::example$graphql/1getAllKsSchema.graphql[]
----
--

Result::
+
--
[source,plaintext]
----
include::example$result/gql_1getAllKsSchema.result[]
----
--
====

Note that the result lists the current schema version for every loaded schema.

For a particular version of a keyspace schema:

[tabs]
====
graphQL command::
+
--
[source,shell]
----
include::example$graphql/1getParticularKsSchema.graphql[]
----
--

Result::
+
--
[source,plaintext]
----
include::example$result/gql_1getParticularKsSchema.result[]
----
--
====

// end::CheckKSSchema[]

// tag::UndeploySchema[]
=== Undeploy schema

To undeploy an existing schema, use the following mutation.

[tabs]
====
graphQL command::
+
--
[source,shell]
----
include::example$graphql/1Undeploy.graphql[]
----
--

Result::
+
--
[source,plaintext]
----
include::example$result/gql_1Undeploy.result[]
----
--
====

The keyspace name and schema version must be supplied.
One option is available, `force`, to force an erasure of the schema.
// end::UndeploySchema[]

== Interact with data stored in objects

// tag::WriteData[]
=== Insert data

If you have created schema for insertion, now you are ready to write data into the database.

First, let's navigate to your new keyspace `library` inside the playground.
Change the location to
http://localhost:8080/graphql/library[http://localhost:8080/graphql/library]
and add a couple of books:

[tabs]
====
graphQL command::
+
--
[source,shell]
----
include::example$graphql/1insert2Books.graphql[]
----
--

Result::
+
--
[source,plaintext]
----
include::example$result/gql_1insert2Books.result[]
----
--
====

The insertion is straightforward.
The title and author are specified, and the title is returned in response to a
successful insertion.
Only the required fields must be specified, and any fields can be returned in
the response.
This same operation can update stored data, as insertions are upserts in all cases.

// LLP: ********** I  NEED TO ADD A CONDITIONAL IFNOTEXISTS INSERT! ********
// end::WriteData[]

// tag::WriteAdvData[]
==== Conditional insertion

[tabs]
====
graphQL command::
+
--
[source,shell]
----
include::example$graphql/1createPayloadConditional.graphql[]
----
--

Result::
+
--
[source,plaintext]
----
include::example$result/gql_1createPayloadConditional.result[]
----
--
====

//==== Insertion options

//Three insertion options are configurable during data insertion or updating:

//* https://docs.datastax.com/en/dse/6.8/dse-arch/datastax_enterprise/dbInternals/dbIntConfigConsistency.html[consistency level]
//* https://docs.datastax.com/en/dse/6.8/dse-arch/datastax_enterprise/dbInternals/dbIntConfigSerialConsistency.html[serial consistency level]
//* https://docs.datastax.com/en/dse/6.8/cql/cql/cql_using/useExpire.html[time-to-live (TTL)]

//An example insertion that sets the consistency level and TTL:

//[tabs]
//====
//graphQL command::
//+
//--
//[source,shell]
//----
//include::example$graphql/insertBookWithOption.graphql[]
//----
//--

//Result::
//+
//--
//[source,plaintext]
//----
//include::example$result/gql_insertBookWithOption.result[]
//----
//--
//====

//The serial consistency can also be set with `serialConsistency` in the options,
//if needed.

==== Insert arrays and UDTs

Inserting arrays and UDTs requires a few extra embellishments:

[tabs]
====
graphQL command::
+
--
[source,shell]
----
include::example$graphql/1insert2Readers.graphql[]
----
--

Result::
+
--
[source,plaintext]
----
include::example$result/gql_1insert2Readers.result[]
----
--
====

Note the use of square brackets around arrays of objects, with commas separating
array items.

// end::WriteAdvData[]

// tag::ReadData[]
=== Retrieve data

Let's check that the data was inserted.
Use the query `book` with the primary key to find a book based on its title.
Use http://localhost:8080/graphql/library[http://localhost:8080/graphql/library]
to execute the query in GraphQL playground:

[tabs]
====
graphQL command::
+
--
[source,shell]
----
include::example$graphql/1fetchBook.graphql[]
----
--

Result::
+
--
[source,plaintext]
----
include::example$result/gql_1fetchBook.result[]
----
--
====

// end::ReadData[]

// tag::ReadAdvData[]

It is also possible to find books with a partial primary key. If more than one book
has the same title (partition key), for instance, but different isbn codes (clustering key),
then a listing of all books that match can be retrieved:

[tabs]
====
graphQL command::
+
--
[source,shell]
----
include::example$graphql/1fetchSameBooks.graphql[]
----
--

Result::
+
--
[source,plaintext]
----
include::example$result/gql_1fetchSameBooks.result[]
----
--
====

In both queries, the `title`, `isbn`, and `author` are specified as return results.

To display the contents of a UDT, notice the inclusion of `addresses` and its
embedded fields in the values designated as return values in this query to retrieve the readers:

[tabs]
====
graphQL command::
+
--
[source,shell]
----
include::example$graphql/1fetchReaders.graphql[]
----
--

Result::
+
--
[source,plaintext]
----
include::example$result/gql_1fetchReaders.result[]
----
--
====

In this example, the primary key consists of both `name` and `user_id`, to distinguish
readers who might have the same name.

Stargate only allows combinations of fields that have:
* at most one indexed field in the query
* if no indexed field is present, then all partition key fields must be present
** it's possible to omit some or all of the clustering fields (in which case
  the query may return multiple rows

==== **Filter options for reads**

It's possible to customize the CQL condition of each parameter with `@cql_where`
with the following arguments:

* field: the GraphQL field name to which the condition applies
* predicate: the conditional predicate to use

The filters available are:

|====
| Predicate | GraphQL fields that can have condition applied
| EQ (equal) | partition key, clustering key, regular indexed field
| IN (within)  | partition key, clustering key, regular indexed field
| GT (greater than) | clustering key
| GTE (greater than or equal to) | clustering key
| LT (less than) | clustering key
| LTE (less than or equal to) | clustering key
| CONTAINS | regular indexed field that is a list and has an index target of VALUES
|====

IN example, that finds the books that are listed in the supplied array:
[tabs]
====
graphQL command::
+
--
[source,shell]
----
include::example$graphql/1createQueryWhereIN.graphql[]
----
--

Result::
+
--
[source,plaintext]
----
include::example$result/gql_1createQueryWhereIN.result[]
----
--
====

IN example with 2 partition keys, demonstrating that values for each
can be supplied:

[tabs]
====
graphQL command::
+
--
[source,shell]
----
include::example$graphql/1createQueryWhereIN2PartKey.graphql[]
----
--

Result::
+
--
[source,plaintext]
----
include::example$result/gql_1createQueryWhereIN2PartKey.result[]
----
--
====

GT example, that looks for equality on the partition key, and then a range of
possible values for the clustering field:

[tabs]
====
graphQL command::
+
--
[source,shell]
----
include::example$graphql/1createQueryWhereGT.graphql[]
----
--

Result::
+
--
[source,plaintext]
----
include::example$result/gql_1createQueryWhereGT.result[]
----
--
====

GT example #2, that looks for a book with a title and an isbn code that is
greater than the value supplied:

[tabs]
====
graphQL command::
+
--
[source,shell]
----
include::example$graphql/1createQueryWhereGT-2.graphql[]
----
--

Result::
+
--
[source,plaintext]
----
include::example$result/gql_1createQueryWhereGT-2.result[]
----
--
====

LT example, that looks for a book with the same title and an isbn code that is
less than the value supplied:

[tabs]
====
graphQL command::
+
--
[source,shell]
----
include::example$graphql/1createQueryWhereLT.graphql[]
----
--

Result::
+
--
[source,plaintext]
----
include::example$result/gql_1createQueryWhereLT.result[]
----
--
====

CONTAINS example that shows how to retrieve a reader that submitted a
supplied review:

[tabs]
====
graphQL command::
+
--
[source,shell]
----
include::example$graphql/1createQueryWhereCONTAINS.graphql[]
----
--

Result::
+
--
[source,plaintext]
----
include::example$result/gql_1createQueryWhereCONTAINS.result[]
----
--
====

// end::ReadAdvData[]

// tag::UpdateData[]
=== Update data

A mutation can be turned into a update operation by starting the mutation
name with `update`.
A mutation will also be an update operation if it is annotated with `@cql_update`.
The mutation must take a single argument that is an input type for a mapped entity.
If successful, the mutation will return a Boolean value.
In order to execute the mutation, all primary key fields and at least one non-primary key
field must be input.

For example, the following mutation and associated query will update a single row:

[tabs]
====
graphQL command::
+
--
[source,shell]
----
include::example$graphql/1queryUpdate.graphql[]
----
--

Result of command::
+
--
[source,plaintext]
----
include::example$result/gql_1queryUpdate.result[]
----
--

New record::
+
--
[source,plaintext]
----
include::example$result/gql_1queryUpdate-2.result[]
----
--
====

[NOTE]
====
Updates are upserts. If the row doesn't exist, it will be created.
If it does exist, it will be updated with the new row data.
====
// end::UpdateData[]

// tag::DeleteData[]
=== Delete data

A mutation can be turned into a delete operation by starting the mutation
name with `delete` or `remove`.
A mutation will also be a delete operation if it is annotated with `@cql_delete`.
The mutation must take a single argument that is an input type for a mapped entity,
or individual primary key arguments like retrieving operations.
If successful, the mutation will return a Boolean value.

At runtime, all partition key fields must be present, and a prefix of the
clustering columns can be present (if using a single object argument, other
  fields will be ignored).
The delete operation targets a single row if it operates on a full primary key,
or multiple rows otherwise.

Let's add another book "Pride and Prejudice" with an `insertBook()`, so that you can delete
the book using `deleteBook()` to illustrate deleting data:

[tabs]
====

insert book::
+
--
[source,shell]
----
include::example$graphql/1insertPapBook.graphql[]
----
--

delete book::
+
--
[source,shell]
----
include::example$graphql/1deleteBook.graphql[]
----
--

delete result::
+
--
[source,plaintext]
----
include::example$result/gql_1deleteBook.result[]
----
--
====

To check for the existence of a record before deleting, use either method discussed above.
This example shows the use of the directive `@cql_delete( ifExists: true)`:

[tabs]
====
mutation::
+
--
[source,shell]
----
deleteLibCollection(libColl: LibCollectionInput!): Boolean @cql_delete(ifExists: true)
----
--

insert library collection::
+
--
[source,shell]
----
include::example$graphql/1insert4LibColls.graphql[]
----
--

delete book with ifExists::
+
--
[source,shell]
----
include::example$graphql/1deleteLibColl.graphql[]
----
--

delete result::
+
--
[source,plaintext]
----
include::example$result/gql_1deleteLibColl.result[]
----
--
====

// end::DeleteData[]

// tag::Directives[]
== Directives

[cols="20h,~,~"]
|===
| Name | Description | Arguments
| @cql_column | Set type field CQL values
a|
name: String

partitionKey: true/false

clusteringOrder: ASC/DESC

typeHint: String
| @cql_delete | Conditional delete clause, with possible consistency level, serial consistency level, or targetEntity
a|
if Exists: true/false

consistencyLevel: MutationConsistency = ALL/LOCAL_ONE/LOCAL_QUORUM

serialConsistency: SerialConsistency = LOCAL_SERIAL/SERIAL

targetEntity: String
| @cql_entity | Set a type field data type
a|
name: String

target (UDT)
| @cql_increment | Set a type field that will increment on UPDATE
a|
field to increment (counter, set, and list only): String

The default is false, meaning that the value will be appended

prepend: Boolean = false
| @cql_if | Set a type field that the predicate `if <field> <predicate` uses to check condition for  DELETE and UPDATE.
a|
field: String
predicates (EQ, GT, GTE, IN, GT, LTE, and NEQ)
| @cql_index | Create a type field index
a|
name: String

class: (org.apache.cassandra.index.sasi.SASIIndex)

type: (FULL, VALUES)

options: (mode: 'CONTAINS')

target: String
| @cql_input | Identify a type as an input type | name (optional): String
| @cql_insert | Add a conditional clause, consistency level, serial consistency level, or time-to-live (TTL)
a|
ifNotExists: true/false

consistencyLevel: MutationConsistency = ALL/LOCAL_ONE/LOCAL_QUORUM

serialConsistency: SerialConsistency = LOCAL_SERIAL/SERIAL

ttl: String (interpreted in seconds)
| @cql_pagingState | The paging state to inject in the query | N/A
| @cql_payload | Identify a type as a payload type | N/A
| @cql_select | Set response arguments pageSize, limit, with possible consistencyLevel
a|
consistencyLevel: QueryConsistency = ALL/LOCAL_ONE/LOCAL_QUORUM/LOCAL_SERIAL/SERIAL

pageSize: Int

limit: Int
| @cql_update | Set an insertion to be an update, with possible conditional clause, consistency level, serial consistency level, time-to-live (TTL), or targetEntity
a|
ifExists: true/false

consistencyLevel: MutationConsistency = ALL/LOCAL_ONE/LOCAL_QUORUM

serialConsistency: SerialConsistency = LOCAL_SERIAL/SERIAL

ttl: String (interpreted in seconds)

targetEntity: String
| @cql_where | Predicates that customize the conditions of a parameter
a|
field: String

predicate (EQ (default), GT, GTE, IN, LT, LTE, CONTAINS)
|===

include::partial$curl_cql_directive.adoc[]
// end::Directives[]
