= Using the Stargate GraphQL API (Schema-first)

Stargate is a data gateway deployed between client applications and a database.
The GraphQL API plugin that exposes CRUD access to data stored in Cassandra tables.

include::partial$graphql-first-desc.adoc[]

include::partial$GQLAPIBlogPost.adoc[]

// tag::prereqsList[]
include::partial$gql-prereqs.adoc[]
// end::prereqsList[]

// not in astra yet
//include::developers-guide:partial$astra_tip.adoc[]

// tag::getDockerImage[]
include::partial$docker_pull.adoc[tag=3x]
// end::getDockerImage[]

// tag::startDocker[]
include::partial$docker_run.adoc[tag=3x]
// end::startDocker[]

== Use the Auth API to generate an auth token
In order to use the Stargate GraphQL API, an authorization token must be
generated to access the interface. A REST API token is used for this purpose.

// generate the auth token
include::partial$gen_auth_token.adoc[]

You will need to add this token to the GraphQL Playground in order to authorize
your GraphQL requests. Copy the value after `"authToken"` to use later.

// LLP - 05.07.21 These two sections are in graphql.adoc
//include::graphql.adoc[tag=UsingGraphQLPlayground]
//include::graphql.adoc[tag=UsingPostman]

== Create or delete schema

In order to use the GraphQL API, you must xref:graphql-first-using.adoc#_deploy_schema[deploy schema]
that defines the types, mutations, and queries.
However, a keyspace, a container that stores the data, must first be created.

// tag::CreateKS[]
=== Create a keyspace

Before you can start using the GraphQL API, you must first create a Cassandra
keyspace in your database.

// LLP: need to check how to write this - it's migration...If you are connecting
// to a Cassandra database with existing schema, you can skip this step.

Inside the GraphQL playground, navigate to
http://localhost:8080/graphql-schema[http://localhost:8080/graphql-schema]
and create a keyspace by executing the following mutation:

[source, plaintext]
----
include::example$graphql/createKeyspace.graphql[]
----
For each keyspace created in your Cassandra schema, a new path is created under
the `graphql-path` root (default is: `/graphql`). For example, the mutation just
executed creates a path `/graphql/library` for the `library` keyspace when
Cassandra creates the keyspace.

Add the auth token to the HTTP Headers box in the lower lefthand corner:

[source, plaintext]
----
{
  "X-Cassandra-Token":"bff43799-4682-4375-99e8-23c8a9d0f304"
}
----

[IMPORTANT]
====
Notice that the key for this JSON token is different than the value that the
generate token has. It is `X-Cassandra-Token`, not `auth-token`.
====

Now run the mutation to create the keyspace. You should see a return value of:

[source, plaintext]
----
include::example$result/gql_createKeyspace.result[]
----
// end::CreateKS[]

// tag::DeleteKS[]
=== Delete a keyspace

You can delete a keyspace. All tables and table data will be deleted along with
the keyspace schema.

[source, plaintext]
----
include::example$graphql/dropKeyspace.graphql[]
----
// end::DeleteKS[]

=== A note about what schema is

A full GraphQL schema that will be
xref:graphql-first-using.adoc#_deploy_schema[deployed] can
include user-defined types (UDTs), object types, indexes, queries, mutations, and payload
types. The next sections describes the definition of these items before discussing
how to deploy the schema once created.

[TIP]
====
Do you want to understand deployment first?
Read xref:graphql-first-using.adoc#_deploy_schema[Deploy Schema].
====

// tag::CreateUDT[]
=== Create a user-defined type (UDT)

User-defined types (UDTs) can be created as GraphQL object types.
UDTs are optional, but if you wish to use a UDT in another object type definition,
you'll want to create the UDT first.
Once created, you can include the type in the schema deployed via the GraphQL playground.
Here are two examples that create a UDT called `Address` that includes a street, city, state, and zipcode,
and a UDT called `Review` that includes a book title, comment, rating and review data.

[tabs]
====
Address UDT::
+
--
[source,shell]
----
include::example$graphql/1createUDTAddress.graphql[]
----
--

Review UDT::
+
--
[source,shell]
----
include::example$graphql/1createUDTReview.graphql[]
----
--
====

// USE asciidoc callouts to explain? a la https://docs.couchbase.com/home/contribute/code-blocks.html#callouts
These types have some Cassandra-specific features, in addition to the typical format
of a GraphQL type.
To denote that the type is stored as a UDT in Cassandra, `@cql_entity(target: UDT)`
is added to the initial line.

To avoid duplicating the type as both an input type and output type, add `@cql_input`
to generate an `AddressInput` type with the same fields as the type `Address`
in the GraphQL schema.

Standard CamelCase is used to name the fields, but the Cassandra column name can be
named with an alternative using `@cql_column(name: "book_title")`.
In Cassandra, CamelCase names must be double-quoted, so this particular field name is
both GraphQL friendly (`bookTitle`) and CQL friendly (`book_title`).
// end::CreateUDT[]

// tag::DataTypes[]
=== Data types

A column's CQL data type is inferred from the GraphQL field type.
GraphQL's built-in scalar types are mapped:

[options="header",footer"]
|====
| GraphQL | CQL
| ID      | uuid
| String  | varchar
| Int     | int
| Float   | double
| Boolean | boolean
|====

In addition, Stargate provides a set of custom scalar types that map directly
to the CQL types of the same name:
Uuid, TimeUuid, Inet, Date, Duration, BigInt, Counter, Ascii, Decimal, Varint,
Float32, Blob, SmallInt, TinyInt, Timestamp, Time.

Sets and lists are defined by custom typed arrays. Maps and tuples are not
supported, but UDTs can be used to create the same functionality.
// end::DataTypes[]

// tag::CreateObjectTypes[]
=== Create object types

The most basic components of a GraphQL schema are object types, which just
represent a kind of object you can fetch from your service, and specify the
fields contained in the object.

[tabs]
====
Book type::
+
--
[source,shell]
----
include::example$graphql/1createTableBook.graphql[]
----
--

Reader type::
+
--
[source,shell]
----
include::example$graphql/1createTableReader.graphql[]
----
--
====

Although the types defined for UDTs and these examples are not fundamentally different,
a few new features are illustrated here.

In the Book type, there are additional `@cql_column` parameters defined.
It is possible to define the partition key and clustering keys are shown, by
using `partitionKey: true` and `clusteringOrder: ASC`, respectively.
The default clustering order is `ASC`, or ascending.
Information about partition keys and clustering keys can be found in the
https://cassandra.apache.org/doc/latest/cql/[CQL reference].

[IMPORTANT]
====
If no field has a `partitionKey: true`, but the first field is of data type
ID, Uuid, or TimeUuid, then that field is used as the partition key in the database.
====

A standard GraphQL type feature is displayed in these types, the required fields
denoted by `String!` and `Uuid!` that include the exclamation mark.

The fields `reviews` and `address` are defined as arrays by the addition of square brackets,
`reviews: [Review]`.
Note that these two fields are arrays of the UDTs previously defined.

Lastly, `@cql_column` can be used to provide a hint to Cassandra that specifies
custom field types, such as a set of strings, `@cql_column(typeHint: "set<varchar>")`.
The only valid `typeHints` using a set instead of a list, or making a CQL type frozen.
// end::CreateObjectTypes[]

// tag::CreateIndexes[]
=== Create indexes

Cassandra supports indexing any regular, non-primary key fields in an object type.
A field will  be indexed if `@cql_index` is added to the field definition.
Indexed fields can be used as parameters in queries.

[tabs]
====

Reader type::
+
--
[source,shell]
----
include::example$graphql/1createReaderIndex.graphql[]
----
--
====

The directive `@cql_index` has the following optional arguments:

|====
| Argument  | Default | Description
| name | Generated | Custom index name
| class | Secondary index | Custom index class, such as SAI
| target | VALUES | Specifies set and list index type. Options are FULL and VALUES
| options | N/A | Any options to pass to the underlying index query.
|====
// end::CreateIndexes[]

// tag::CreateQueries[]
=== Create queries

Most types in your schema will just be normal object types, but there are two types
that are special, the Query type and the Mutation type.
Every GraphQL service has a query type.
Mutation types are optional.
These types are special because they define the entry point of every GraphQL query.

Queries

[tabs]
====
Queries::
+
--
[source,shell]
----
include::example$graphql/1createQuery.graphql[]
----
--
====

These queries each specify the fields required and optional, as well as the input
type.

In the case of `book`, `title` is a required column, and `author` is an optional field
input to retrieve a particular book. Because you specified `@cql_input` in the
object type, a book can be the input to this query,
while `[Book]` specifies that the output will be an array of books.
// end::CreateQueries[]

// tag::CreateMutations[]
=== Create mutations

Mutations work in a similar way  to queries.
Define fields in the mutation type, and you can specify those fields in your queries.

[tabs]
====
Mutations::
+
--
[source,shell]
----
include::example$graphql/1createOperations.graphql[]
----
--
====

For mutations, notice the use of the input type `book:BookInput!` to define that the
type submitted to the mutation is a `book`.
`insertBook` will insert a book, `insertReader` will insert a reader, and `deleteBook`
and `deleteReader` are Boolean operations.

==== Conditional insertion

A mutation can be turned into a conditional insertion operation by ending the mutation
name with `ifNotExists`.
However, it may be useful to know if the insertion is successfully applied.
In that case, see payload type below to see how a boolean field `applied` can
be added to the response from insertions or annotating it with @cql_insert(ifNotExists: true)
// end::CreateMutations[]

// tag::CreatePayloadTypes[]
=== Create payload types

Payloads types are not mapped to the database.
They only serve as wrappers of an operation's response.
They typically pass a more complex object than just an entity. For example,
you can add fields that check the `applied` status for a conditional query, or
the `pagingState`.

In this example, a payload type `SelectBookResult` is created that accepts an array
of books as the input. The associated query can use the required `title` and optional `pagingState`
as input, and will return an array of books along with the `pagingState`.

[tabs]
====
Payload type::
+
--
[source,shell]
----
include::example$graphql/1createQueryPageSize.graphql[]
----
--
====

There is an additional decoration `@cql_select` that can define two parameters:

* limit: the maximum total number of results to return (type Int)
* pageSize: how many results to return by page if the query is paginated (type Int)

This example includes `pageSize`.

An example of retrieving data using this query is found xref:graphql-first-using.adoc#_retrieve_data[below].

Often, you wish to know if an operation was successful. Creating a payload type that
uses a boolean field `applied` can definitively answer if a conditional operation
completes correctly.

Create a payload type that uses your standard object type as a field, along with `applied`:

[tabs]
====
Payload type with conditional::
+
--
[source,shell]
----
include::example$graphql/1createPayloadConditional.graphql[]
----
--
====

If the conditional insert is successful (the row did not exist), then applied
will be true and book will echo back the data that was just inserted;
otherwise, applied will be false and book will be the existing data.

// end::CreatePayloadTypes[]

// tag::DeploySchema[]
== Deploy schema

=== Deploy schema manually

Now that you have created GraphQL types, queries, and mutations, it's time to deploy the schema.
Recall that the corresponding CQL schema is inferred and created from the GraphQL schema
submitted.

Inside the GraphQL playground, navigate to http://localhost:8080/graphql-admin and create
the schema to deploy to a previously defined keyspace:

[tabs]
====
graphQL command::
+
--
[source,shell]
----
include::example$graphql/1createDeploy.graphql[]
----
--

Result::
+
--
[source,plaintext]
----
include::example$result/gql_1createDeploy.result[]
----
--
====

A defined mutation `deploySchema` is executed.
The keyspace is specified, along with the schema, specified between triple quotes (`"""`).

A number of additional options are used in the following manner:

|====
| Option | Default | Description
| expectedVersion | N/A | Each schema is assigned a unique version number. If the current deployment is a modification, the version must be supplied.
| dryRun | false | To test in a dryrun, use `dryRun: true`
| force | false |Force a schema change
| migrationStrategy | ADD_MISSING_TABLES_AND_COLUMNS | USE_EXISTING, ADD_MISSING_TABLES, ADD_MISSING_TABLES_AND_COLUMNS, DROP_AND_RECREATE_ALL, DROP_AND_RECREATE_IF_MISMATCH
|====

Two items are returned in this example, the `version` that is assigned to the schema,
and `cqlChanges`, the status of whether CQL changes occurred due to the schema deployment.
Other responses are `logs` and `query`.

The `migrationStrategy` option needs further explanation on how `deploySchema`
updates the underlying CQL schema, based on the options argument.
The available strategies are:

ADD_MISSING_TABLES_AND_COLUMNS (default)::
Create CQL tables and UDTs that don't already exist.
For those that exist, add any missing columns.
Partition keys and clustering columns cannot be added after initial creation.
This strategy will fail if the column already exists with a different data type.
USE_EXISTING::
Don't do anything. This is the most conservative strategy.
All CQL tables and UDTs must match, otherwise the deployment is aborted.
ADD_MISSING_TABLES::
Create CQL tables and UDTs that don't already exist.
Those that exist must match, otherwise the deployment is aborted.
DROP_AND_RECREATE_ALL::
Drop and recreate all CQL tables and UDTs.
This is a destructive operation: any existing data will be lost.
DROP_AND_RECREATE_IF_MISMATCH::
Drop and recreate only the CQL tables and UDTs that don't match.
This is a destructive operation: any existing data in the recreated tables will be lost.
Tables that are not recreated will retain their data.

=== Deploy schema file

Schema can also be deployed to a keyspace using a schema file upload.
This mutation must be executed with a multipart request (note that your operations
  part must declare MIME type application/json).

In this case, `deploySchemaFile` is executed. This query must be executed in the command line
with a cURL command:

[tabs]
====
graphQL command::
+
--
[source,shell]
----
include::example$graphql/1createDeployFile.graphql[]
----
--

Result::
+
--
[source,plaintext]
----
include::example$result/gql_1createDeployFile.result[]
----
--
====
The operations part contains the GraphQL payload. It consists of a
parameterized mutation, which takes a single `$file` argument (note that we
  leave it as null in the payload, because it's going to be set another way).
The `filePart` argument contains the file.
The `map` argument specifies which file goes into which GraphQL variable.

In order to deploy a schema file again, you'll need to supply the `expectedVersion` for
the schema to be replaced:

[tabs]
====
graphQL command::
+
--
[source,shell]
----
include::example$graphql/1DeployFileAgain.graphql[]
----
--

Result::
+
--
[source,plaintext]
----
include::example$result/gql_1DeployFileAgain.result[]
----
--
====

=== Modify schema

To modify the current schema, simply deploy again, supplying the `expectedVersion` as the
current schema's version if you wish to overwrite the definitions. Otherwise, a new schema
with a new version id will be created.
// end::DeploySchema[]


// tag::CheckKSSchema[]
== Check the keyspace schema

To check if the schema exists, execute a GraphQL check in http://localhost:8080/graphql-admin:

For all versions of a keyspace schema:

[tabs]
====
graphQL command::
+
--
[source,shell]
----
include::example$graphql/1getAllKsSchema.graphql[]
----
--

Result::
+
--
[source,plaintext]
----
include::example$result/gql_1getAllKsSchema.result[]
----
--
====

For a particular version of a keyspace schema:

[tabs]
====
graphQL command::
+
--
[source,shell]
----
include::example$graphql/1getParticularKsSchema.graphql[]
----
--

Result::
+
--
[source,plaintext]
----
include::example$result/gql_1getParticularKsSchema.result[]
----
--
====

// end::CheckKSSchema[]

// tag::UndeploySchema[]
== Undeploy schema

To undeploy an existing schema, use the following mutation.

[tabs]
====
graphQL command::
+
--
[source,shell]
----
include::example$graphql/1Undeploy.graphql[]
----
--

Result::
+
--
[source,plaintext]
----
include::example$result/gql_1Undeploy.result[]
----
--
====

The keyspace name and schema version must be supplied.
One option is available, `force`, to force an erasure of the schema.
// end::UndeploySchema[]

== Interact with data stored in tables

// tag::WriteData[]
=== Insert data

If you have created schema for insertion, now you are ready to write data into the database.

First, let's navigate to your new keyspace `library` inside the playground.
Change the location to
http://localhost:8080/graphql/library[http://localhost:8080/graphql/library]
and add a couple of books to the `book` table:

[tabs]
====
graphQL command::
+
--
[source,shell]
----
include::example$graphql/1insert2Books.graphql[]
----
--

Result::
+
--
[source,plaintext]
----
include::example$result/gql_1insert2Books.result[]
----
--
====

The insertion is straightforward.
The title and author are specified, and the title is returned in response to a successful insertion.
Only the required fields must be specified, and any fields can be returned in the response.
This same operation can update stored data, as insertions are upserts in all cases.

// LLP: ********** I  NEED TO ADD A CONDITIONAL IFNOTEXISTS INSERT! ********

// end::WriteData[]

// COMMENTED OUT FOR NOW - NOT IMPLEMENTED BUT MAY BE, SO LEAVE THE TEXT
// tag::WriteAdvData[]
==== Conditional insertion

[tabs]
====
graphQL command::
+
--
[source,shell]
----
include::example$graphql/1createPayloadConditional.graphql[]
----
--

Result::
+
--
[source,plaintext]
----
include::example$result/gql_1createPayloadConditional.result[]
----
--
====

//==== Insertion options

//Three insertion options are configurable during data insertion or updating:

//* https://docs.datastax.com/en/dse/6.8/dse-arch/datastax_enterprise/dbInternals/dbIntConfigConsistency.html[consistency level]
//* https://docs.datastax.com/en/dse/6.8/dse-arch/datastax_enterprise/dbInternals/dbIntConfigSerialConsistency.html[serial consistency level]
//* https://docs.datastax.com/en/dse/6.8/cql/cql/cql_using/useExpire.html[time-to-live (TTL)]

//An example insertion that sets the consistency level and TTL:

//[tabs]
//====
//graphQL command::
//+
//--
//[source,shell]
//----
//include::example$graphql/insertBookWithOption.graphql[]
//----
//--

//Result::
//+
//--
//[source,plaintext]
//----
//include::example$result/gql_insertBookWithOption.result[]
//----
//--
//====

//The serial consistency can also be set with `serialConsistency` in the options,
//if needed.

==== Insert arrays and UDTs

Inserting arrays and UDTs requires a few extra embellishments:

[tabs]
====
graphQL command::
+
--
[source,shell]
----
include::example$graphql/1insert2Readers.graphql[]
----
--

Result::
+
--
[source,plaintext]
----
include::example$result/gql_1insert2Readers.result[]
----
--
====

Note the use of square brackets around arrays of objects, with commas separating
array items.

// end::WriteAdvData[]

// tag::ReadData[]
=== Retrieve data

Let's check that the data was inserted.
Use the query `book` with the primary key to find a book based on its title.
Use http://localhost:8080/graphql/library[http://localhost:8080/graphql/library]
to execute the query in GraphQL playground:

[tabs]
====
graphQL command::
+
--
[source,shell]
----
include::example$graphql/1fetchBook.graphql[]
----
--

Result::
+
--
[source,plaintext]
----
include::example$result/gql_1fetchBook.result[]
----
--
====

// end::ReadData[]

// tag::ReadAdvData[]

It is also possible to find books with a partial primary key. If more than one book
has the same title (partition key), for instance, but different authors (clustering key),
then a listing of all books can be retrieved:

[tabs]
====
graphQL command::
+
--
[source,shell]
----
include::example$graphql/1fetchSameBooks.graphql[]
----
--

Result::
+
--
[source,plaintext]
----
include::example$result/gql_1fetchSameBooks.result[]
----
--
====

In both queries, both the `title` and the `author` are specified as return results.

To display the contents of a UDT, notice the inclusion of `addresses`  and its embedded fields in the values
designated as return values in this query to retrieve the readers:

[tabs]
====
graphQL command::
+
--
[source,shell]
----
include::example$graphql/1fetchReaders.graphql[]
----
--

Result::
+
--
[source,plaintext]
----
include::example$result/gql_1fetchReaders.result[]
----
--
====

In this example, the primary key consists of both `name` and `user_id`, to distinguish
readers who might have the same name.

==== Filter options for reads

It's possible to customize the CQL condition of each parameter with `@cql_where`
with the following arguments:

* field: the GraphQL field name to which the condition applies
* predicate: the conditional predicate to use

The filters available are:

|====
| Predicate | GraphQL fields that can have condition applied
| EQ (equal) | partition key, clustering key, regular indexed field
| IN (within)  | partition key, clustering key, regular indexed field
| GT (greater than) | clustering key
| GTE (greater than or equal to) | clustering key
| LT (less than) | clustering key
| LTE (less than or equal to) | clustering key
| CONTAINS | regular indexed field that is a list and has an index target of VALUES
|====

//* notEq (not equal)
//* containsKey (a map contains the specified key)
//* containsEntry (a map contains the specified key:value pair)

IN example:
[tabs]
====
graphQL command::
+
--
[source,shell]
----
include::example$graphql/1createQueryWhereIN.graphql[]
----
--

Result::
+
--
[source,plaintext]
----
include::example$result/gql_1createQueryWhereIN.result[]
----
--
====

IN example with 2 partition keys

[tabs]
====
graphQL command::
+
--
[source,shell]
----
include::example$graphql/1createQueryWhereIN2PartKey.graphql[]
----
--

Result::
+
--
[source,plaintext]
----
include::example$result/gql_1createQueryWhereIN2PartKey.result[]
----
--
====

// LLP: notice that the "name" of the field in foos is NOT the gql field name
// for example: minCc1 and maxCc1
GT example #1

Equality on the partition key, and range on a clustering field:
foos(
    pk: Int
    minCc1: Int @cql_where(field: "cc1", predicate: GTE)
    maxCc1: Int @cql_where(field: "cc1", predicate: LTE)
): [Foo]


[tabs]
====
graphQL command::
+
--
[source,shell]
----
include::example$graphql/1createQueryWhereGT.graphql[]
----
--

Result::
+
--
[source,plaintext]
----
include::example$result/gql_1createQueryWhereGT.result[]
----
--
====

GT example #2

[tabs]
====
graphQL command::
+
--
[source,shell]
----
include::example$graphql/1createQueryWhereGT-2.graphql[]
----
--

Result::
+
--
[source,plaintext]
----
include::example$result/gql_1createQueryWhereGT-2.result[]
----
--
====

LT example

[tabs]
====
graphQL command::
+
--
[source,shell]
----
include::example$graphql/1createQueryWhereLT.graphql[]
----
--

Result::
+
--
[source,plaintext]
----
include::example$result/gql_1createQueryWhereLT.result[]
----
--
====

CONTAINS example

[tabs]
====
graphQL command::
+
--
[source,shell]
----
include::example$graphql/1createQueryWhereCONTAINS.graphql[]
----
--

Result::
+
--
[source,plaintext]
----
include::example$result/gql_1createQueryWhereCONTAINS.result[]
----
--
====

// end::ReadAdvData[]

// tag::UpdateData[]
=== Update data

A mutation can be turned into a update operation by starting the mutation
name with `update`.
A mutation will also be an update operation if it is annotated with `@cql_update`.
The mutation must take a single argument that is an input type for a mapped entity.
If successful, the mutation will return a Boolean value.
In order to execute the mutation, all primary key fields and at least one non-primary key
field must be input.

For example, the following mutation and associated query will update a single row:

[tabs]
====
graphQL command::
+
--
[source,shell]
----
include::example$graphql/1queryUpdate.graphql[]
----
--

Result::
+
--
[source,plaintext]
----
include::example$result/gql_1queryUpdate.result[]
----
--
====

[NOTE]
====
Updates are upserts. If the row doesn't exist, it will be created.
If it does exist, it will be updated with the new row data.
====
// end::UpdateData[]

// tag::DeleteData[]
=== Delete data

A mutation can be turned into a delete operation by starting the mutation
name with `delete` or `remove`.
A mutation will also be a delete operation if it is annotated with `@cql_delete`.
The mutation must take a single argument that is an input type for a mapped entity,
or individual primary key arguments like retrieving operations.
If successful, the mutation will return a Boolean value.

At runtime, all partition key fields must be present, and a prefix of the
clustering columns can be present (if using a single object argument, other
  fields will be ignored).
The delete operation targets a single row if it operates on a full primary key,
or multiple rows otherwise.

Let's add another book "Pride and Prejudice" with an `insertBook()`, so that you can delete
the book using `deleteBook()` to illustrate deleting data:

[tabs]
====

insert book::
+
--
[source,shell]
----
include::example$graphql/1insertPapBook.graphql[]
----
--

delete book::
+
--
[source,shell]
----
include::example$graphql/1deleteBook.graphql[]
----
--

delete result::
+
--
[source,plaintext]
----
include::example$result/gql_1deleteBook.result[]
----
--
====

To check for the existence of a record before deleting, use either method discussed above.
This example shows the use of the directive `@cql_delete( ifExists: true)`:

[tabs]
====
mutation::
+
--
[source,shell]
----
deleteLibCollection(libColl: LibCollectionInput!): Boolean @cql_delete(ifExists: true)
----
--

insert library collection::
+
--
[source,shell]
----
include::example$graphql/1insert4LibColls.graphql[]
----
--

delete book with ifExists::
+
--
[source,shell]
----
include::example$graphql/1deleteLibColl.graphql[]
----
--

delete result::
+
--
[source,plaintext]
----
include::example$result/gql_1deleteLibColl.result[]
----
--
====

// end::DeleteData[]


// LLP: doublecheck the table below before releasing
// tag::Directives[]
== Directives

|===
| Name | Description | Arguments
| @cql_column | Set type field CQL values | name, partitionKey, clusteringOrder, typeHint
| @cql_delete | Conditional delete clause | if Exists: true
| @cql_entity | Set a type field data type | name, target (UDT)
| @cql_payload | Identify a type as a payload type | N/A
| @cql_index | Create a type field index | name, class (org.apache.cassandra.index.sasi.SASIIndex), type, options (mode: 'CONTAINS')
| @cql_input | Identify a type as an input type | N/A
| @cql_insert | Add a conditional clause | ifNotExists: true
| @cql_pagingState | The paging state to inject in the query | N/A
| @cql_select | Set response arguments | pageSize, limit
| @cql_update | Set an insertion to be an update | N/A
| @cql_where | Predicates that customize the conditions of a parameter | field, predicate (EQ (default), IN, GT, GTE, LT, LTE, CONTAINS)
|===
// end::Directives[]

// LLP: is this true?
// I'll need a section that shows how connecting to an existing C* cluster will automatically
// create the graphql endpoints!
